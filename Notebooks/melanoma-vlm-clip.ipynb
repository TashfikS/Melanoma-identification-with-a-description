{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:49.260771Z",
     "iopub.status.busy": "2025-04-05T09:14:49.260477Z",
     "iopub.status.idle": "2025-04-05T09:14:49.889220Z",
     "shell.execute_reply": "2025-04-05T09:14:49.888412Z",
     "shell.execute_reply.started": "2025-04-05T09:14:49.260739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Cluster similar classes into common one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:49.890474Z",
     "iopub.status.busy": "2025-04-05T09:14:49.890031Z",
     "iopub.status.idle": "2025-04-05T09:14:49.895719Z",
     "shell.execute_reply": "2025-04-05T09:14:49.894919Z",
     "shell.execute_reply.started": "2025-04-05T09:14:49.890425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "diagnosis_map = {\n",
    "    # Benign (0)\n",
    "    \"nevus\": 0, \"solar lentigo\": 0, \"dermatofibroma\": 0, \"vascular lesion\": 0, \"nev\": 0, \"sek\": 0,\n",
    "    \"seborrheic keratosis\": 0,\n",
    "    \"blue nevus\": 0, \"congenital nevus\": 0, \"dermal nevus\": 0, \"seborrheic keratosis\": 0,\n",
    "    \"nv\": 0, \"nevus\": 0, \"bkl\": 0, \"benign keratosis\": 0, \"df\": 0, \"dermatofibroma\": 0,\n",
    "    \"vasc\": 0, \"vascular\": 0,\n",
    "    \"Intradermal Nevus\": 0, \"common nevus\":0,\n",
    "    # Intermediate Benign (1)\n",
    "    \"atypical melanocytic proliferation\": 1, \"actinic keratosis\": 1, \"lichenoid keratosis\": 1,\n",
    "    \"ack\": 1, \"akiec\": 1, \"atypical nevus\":1,\n",
    "    # Intermediate Melanoma (2)\n",
    "    \"melanoma (in situ)\": 2, \"melanoma (<0.76 mm)\": 2, \"lentigo maligna\": 2,\n",
    "    \"atypical spitz tumor\": 2,\n",
    "    # Melanoma (3)\n",
    "    \"melanoma\": 3, \"melanoma metastasis\": 3, \"melanoma (>0.76 mm)\": 3,\n",
    "    \"mel\": 3, \"Nodular Melanoma\": 3, \"melanoma (0.76 to 1.5 mm)\": 3,\n",
    "    \"melanoma (more than 1.5 mm)\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ From .TXT to .CSV (For PH2 Dataset)\n",
    "This cell does the necessary string manupulation to adapt the .CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:49.896595Z",
     "iopub.status.busy": "2025-04-05T09:14:49.896377Z",
     "iopub.status.idle": "2025-04-05T09:14:49.935177Z",
     "shell.execute_reply": "2025-04-05T09:14:49.934533Z",
     "shell.execute_reply.started": "2025-04-05T09:14:49.896577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "# Legend mappings remain the same\n",
    "clinical_diag_map = {\n",
    "    \"0\": \"Common Nevus\",\n",
    "    \"1\": \"Atypical Nevus\",\n",
    "    \"2\": \"Melanoma\"\n",
    "}\n",
    "\n",
    "asymmetry_map = {\n",
    "    \"0\": \"Fully Symmetric\",\n",
    "    \"1\": \"Symetric in 1 axe\",\n",
    "    \"2\": \"Fully Asymmetric\"\n",
    "}\n",
    "\n",
    "feature_map = {\n",
    "    \"A\": \"Absent\",\n",
    "    \"AT\": \"Atypical\",\n",
    "    \"P\": \"Present\",\n",
    "    \"T\": \"Typical\"\n",
    "}\n",
    "\n",
    "colors_map = {\n",
    "    \"1\": \"White\",\n",
    "    \"2\": \"Red\",\n",
    "    \"3\": \"Light-Brown\",\n",
    "    \"4\": \"Dark-Brown\",\n",
    "    \"5\": \"Blue-Gray\",\n",
    "    \"6\": \"Black\"\n",
    "}\n",
    "\n",
    "# Read the file\n",
    "with open(\"/kaggle/input/ph2dataset/PH2Dataset/PH2_dataset.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Get the header line\n",
    "header_line = lines[0].strip()\n",
    "header_line = re.sub(r'^\\|\\||\\|\\|$', '', header_line)  # Remove leading/trailing ||\n",
    "\n",
    "# Split by both single and double pipes\n",
    "header_parts = re.split(r'\\|\\||\\|', header_line)\n",
    "header = [part.strip() for part in header_parts if part.strip()]\n",
    "\n",
    "# Process data rows\n",
    "processed_rows = []\n",
    "for line in lines[1:]:\n",
    "    if not line.strip() or line.startswith(\"||---\"):\n",
    "        continue\n",
    "\n",
    "    # Clean the line\n",
    "    clean_line = line.strip()\n",
    "    clean_line = re.sub(r'^\\|\\||\\|\\|$', '', clean_line)  # Remove leading/trailing ||\n",
    "\n",
    "    # Split by both single and double pipes\n",
    "    parts = re.split(r'\\|\\||\\|', clean_line)\n",
    "    row_data = [part.strip() for part in parts]\n",
    "\n",
    "    # Create a dictionary for this row with all columns\n",
    "    row_dict = {}\n",
    "\n",
    "    # Add data for each column, using empty string for missing values\n",
    "    for i, field_name in enumerate(header):\n",
    "        if i >= len(row_data):\n",
    "            value = \"\"\n",
    "        elif i == 2 and row_data[i]:  # Clinical Diagnosis\n",
    "            value = clinical_diag_map.get(row_data[i], row_data[i])\n",
    "        elif i == 3 and row_data[i]:  # Asymmetry\n",
    "            value = asymmetry_map.get(row_data[i], row_data[i])\n",
    "        elif i >= 4 and i <= 8 and row_data[i]:  # Features\n",
    "            value = feature_map.get(row_data[i], row_data[i])\n",
    "        elif i == 9 and row_data[i]:  # Colors\n",
    "            value = \" \".join(colors_map.get(v, v) for v in row_data[i].split())\n",
    "        else:\n",
    "            value = row_data[i]\n",
    "\n",
    "        row_dict[field_name] = value\n",
    "\n",
    "    processed_rows.append(row_dict)\n",
    "\n",
    "# In convert-to-csv.py, modify the final section:\n",
    "# Write to CSV with only first 200 rows\n",
    "with open(\"PH2_dataset.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for row in processed_rows[:200]:  # Only write first 200 rows\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Conversion complete. CSV saved as PH2_dataset.csv with {len(processed_rows)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Define Paths & load metadata\n",
    "Sets file paths and load metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:49.937171Z",
     "iopub.status.busy": "2025-04-05T09:14:49.936987Z",
     "iopub.status.idle": "2025-04-05T09:14:50.037335Z",
     "shell.execute_reply": "2025-04-05T09:14:50.036658Z",
     "shell.execute_reply.started": "2025-04-05T09:14:49.937156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/kaggle/input'\n",
    "FINAL_METADATA_PATH = \"/kaggle/working/unified_metadata.csv\"\n",
    "AUGMENTED_DATA_PATH = \"/kaggle/working/augmented_data/\"\n",
    "AUGMENTED_METADATA_PATH = \"/kaggle/working/augmented_metadata.csv\"\n",
    "TRAIN_METADATA_PATH = \"/kaggle/working/train_df.csv\"\n",
    "VAL_METADATA_PATH = \"/kaggle/working/validation_df.csv\"\n",
    "TEST_METADATA_PATH = \"/kaggle/working/test_df.csv\"\n",
    "\n",
    "# Example usage for each metadata file:\n",
    "pad_df = pd.read_csv('/kaggle/input/skin-cancer/metadata.csv')\n",
    "darm_df = pd.read_csv('/kaggle/input/derm7pt/release_v0/meta/meta.csv')\n",
    "ham_df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n",
    "ph2_df = pd.read_csv('/kaggle/working/PH2_dataset.csv')\n",
    "\n",
    "ham_df.rename(columns={'image_id':'image_id', 'dx':'diagnosis'}, inplace=True)\n",
    "pad_df.rename(columns={'img_id':'image_id','diagnostic':'diagnosis'}, inplace=True)\n",
    "darm_df.rename(columns={'case_id':'image_id'}, inplace=True)\n",
    "ph2_df.rename(columns={'Name':'image_id', 'Clinical Diagnosis': 'diagnosis'}, inplace=True)\n",
    "\n",
    "ham_df['diagnosis_numeric'] = ham_df['diagnosis'].str.lower().map(diagnosis_map)\n",
    "pad_df['diagnosis_numeric'] = pad_df['diagnosis'].str.lower().map(diagnosis_map)\n",
    "darm_df['diagnosis_numeric'] = darm_df['diagnosis'].str.lower().map(diagnosis_map)\n",
    "ph2_df['diagnosis_numeric'] = ph2_df['diagnosis'].str.lower().map(diagnosis_map)\n",
    "\n",
    "ham_df['dataset_source'] = 'HAM10000'\n",
    "pad_df['dataset_source'] = 'PAD-UFES-20'\n",
    "darm_df['dataset_source'] = 'DERM7PT'\n",
    "ph2_df['dataset_source'] = 'PH2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Metadata modification & merging\n",
    "This cell filters out targeted columns & rows from all datasets and merging the all metadata files after preparing image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:14:50.038842Z",
     "iopub.status.busy": "2025-04-05T09:14:50.038576Z",
     "iopub.status.idle": "2025-04-05T09:15:15.553078Z",
     "shell.execute_reply": "2025-04-05T09:15:15.552297Z",
     "shell.execute_reply.started": "2025-04-05T09:14:50.038811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Merge explicitly\n",
    "# unified_df = pd.concat([df_isic, df_ham, df_pad, df_derm7pt, df_ph2], ignore_index=True)\n",
    "unified_df = pd.concat([ham_df, pad_df, darm_df, ph2_df], ignore_index=True)\n",
    "unified_df.dropna(subset=['diagnosis_numeric'], inplace=True)\n",
    "print(unified_df[\"dataset_source\"].unique())\n",
    "\n",
    "# Explicit image path generation\n",
    "def generate_image_path(row):\n",
    "    source, image_id = row['dataset_source'], row['image_id']\n",
    "    # BASE_DIR = '/kaggle/input'\n",
    "\n",
    "    # if source == 'ISIC':\n",
    "    #     return f\"{BASE_DIR}/all-isic-data-20240629/images/{image_id}.jpg\"\n",
    "\n",
    "    if source == 'HAM10000':\n",
    "        for part in ['HAM10000_images_part_1', 'HAM10000_images_part_2']:\n",
    "            path = f\"{base_dir}/skin-cancer-mnist-ham10000/{part}/{image_id}.jpg\"\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "\n",
    "    elif source == 'PAD-UFES-20':\n",
    "        for part in [1,2,3]:\n",
    "            path = f\"{base_dir}/skin-cancer/imgs_part_{part}/imgs_part_{part}/{image_id}\"\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "\n",
    "    elif source == 'DERM7PT':\n",
    "        if pd.notnull(row['derm']):\n",
    "            return f\"{base_dir}/derm7pt/release_v0/images/{row['derm']}\"\n",
    "        elif pd.notnull(row['clinic']):\n",
    "            return f\"{base_dir}/derm7pt/release_v0/images/{row['clinic']}\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    elif source == 'PH2':\n",
    "        return f\"{base_dir}/ph2dataset/PH2Dataset/PH2_Dataset_images/{image_id}/{image_id}_Dermoscopic_Image/{image_id}.bmp\"\n",
    "\n",
    "unified_df['image_path'] = unified_df.apply(generate_image_path, axis=1)\n",
    "unified_df.dropna(subset=['image_path', 'diagnosis_numeric'], inplace=True)\n",
    "print(unified_df[\"dataset_source\"].unique())\n",
    "columns_to_keep = ['image_id', 'diagnosis', 'diagnosis_numeric', 'dataset_source', 'image_path']\n",
    "unified_df = unified_df[columns_to_keep]\n",
    "unified_df.to_csv(FINAL_METADATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Augmentation Definition\n",
    "This cell does the augmentation & saves the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:15:15.554297Z",
     "iopub.status.busy": "2025-04-05T09:15:15.553981Z",
     "iopub.status.idle": "2025-04-05T09:15:21.002610Z",
     "shell.execute_reply": "2025-04-05T09:15:21.001921Z",
     "shell.execute_reply.started": "2025-04-05T09:15:15.554264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def generate_augmented_df(original_df, target_count, transform, save_dir):\n",
    "    \"\"\"\n",
    "    Generates augmented images and returns new DataFrame with paths & labels.\n",
    "    Saves images to disk in save_dir.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    augmented_records = []\n",
    "    existing_count = len(original_df)\n",
    "    needed = target_count - existing_count\n",
    "\n",
    "    print(f\"Original: {existing_count}, Target: {target_count}, Augmenting: {needed}\")\n",
    "\n",
    "    augment_idx = 0\n",
    "    while len(augmented_records) < needed:\n",
    "        for idx, row in original_df.iterrows():\n",
    "            if len(augmented_records) >= needed:\n",
    "                break\n",
    "\n",
    "            img_path = row['image_path']\n",
    "            label = row['diagnosis_numeric']\n",
    "\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            augmented = transform(image=image)['image']\n",
    "\n",
    "            new_filename = f\"aug_{label}_{augment_idx}.jpg\"\n",
    "            save_path = os.path.join(save_dir, new_filename)\n",
    "            aug_img_np = augmented.permute(1, 2, 0).cpu().numpy()\n",
    "            aug_img_np = np.clip(aug_img_np * 255.0, 0, 255).astype(np.uint8)\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(aug_img_np, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            augmented_records.append({'image_path': save_path, 'diagnosis_numeric': label, 'original_image_path': img_path})\n",
    "            augment_idx += 1\n",
    "\n",
    "    new_df = pd.concat([original_df, pd.DataFrame(augmented_records)], ignore_index=True)\n",
    "    return new_df\n",
    "\n",
    "def balance_custom_classes(df, transform, save_root):\n",
    "    \"\"\"\n",
    "    Custom-balanced class augmentation strategy:\n",
    "    Benign -> 7000 (downsample)\n",
    "    Melanoma -> 5000 (augment)\n",
    "    Intermediate Benign -> 3000 (augment)\n",
    "    Intermediate Melanoma -> 1000 (augment)\n",
    "    \"\"\"\n",
    "    class_targets = {\n",
    "        0: 7000,  # Benign\n",
    "        3: 5000,  # Melanoma\n",
    "        1: 3000,  # Intermediate Benign\n",
    "        2: 1000   # Intermediate Melanoma\n",
    "    }\n",
    "\n",
    "    final_df_list = []\n",
    "\n",
    "    for cls, target_count in class_targets.items():\n",
    "        class_df = df[df['diagnosis_numeric'] == cls]\n",
    "        existing_count = len(class_df)\n",
    "\n",
    "        print(f\"\\nClass {cls}: Existing samples = {existing_count}\")\n",
    "\n",
    "        if existing_count > target_count:\n",
    "            class_df = class_df.sample(target_count, random_state=42).reset_index(drop=True)\n",
    "            print(f\"Downsampled to {target_count}\")\n",
    "            final_df_list.append(class_df)\n",
    "\n",
    "        elif existing_count < target_count:\n",
    "            save_dir = os.path.join(save_root, f\"aug_class_{cls}\")\n",
    "            class_aug_df = generate_augmented_df(class_df, target_count, transform, save_dir)\n",
    "            final_df_list.append(class_aug_df)\n",
    "\n",
    "        else:\n",
    "            final_df_list.append(class_df)\n",
    "\n",
    "    final_balanced_df = pd.concat(final_df_list, ignore_index=True)\n",
    "    return final_balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Augmentation Code Execution\n",
    "Executes a general part of the augmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:15:21.003689Z",
     "iopub.status.busy": "2025-04-05T09:15:21.003310Z",
     "iopub.status.idle": "2025-04-05T09:17:35.830142Z",
     "shell.execute_reply": "2025-04-05T09:17:35.829211Z",
     "shell.execute_reply.started": "2025-04-05T09:15:21.003667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Augmentation to apply to the intermediate classes\n",
    "augment_pipeline = A.Compose([\n",
    "    A.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ColorJitter(p=0.3),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "df = pd.read_csv(FINAL_METADATA_PATH)\n",
    "\n",
    "augmented_metadata_df = balance_custom_classes(df, transform=augment_pipeline, save_root=AUGMENTED_DATA_PATH)\n",
    "augmented_metadata_df.to_csv(AUGMENTED_METADATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Prompt creation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-05T09:17:35.831258Z",
     "iopub.status.busy": "2025-04-05T09:17:35.831033Z",
     "iopub.status.idle": "2025-04-05T09:17:35.842225Z",
     "shell.execute_reply": "2025-04-05T09:17:35.841366Z",
     "shell.execute_reply.started": "2025-04-05T09:17:35.831228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_descriptive_prompt(row):\n",
    "    parts = []\n",
    "\n",
    "    # Diagnosis label mapping for readability\n",
    "    diagnosis_mapping = {\n",
    "        \"bkl\": \"benign keratosis-like lesion\",\n",
    "        \"nv\": \"melanocytic nevus\",\n",
    "        \"mel\": \"melanoma\",\n",
    "        \"bcc\": \"basal cell carcinoma\",\n",
    "        \"akiec\": \"actinic keratosis\",\n",
    "        \"vasc\": \"vascular lesion\",\n",
    "        \"df\": \"dermatofibroma\"\n",
    "    }\n",
    "\n",
    "    # General patient info\n",
    "    sex = str(row.get(\"sex\") or row.get(\"gender\", \"\")).strip().lower()\n",
    "    age = row.get(\"age\") or row.get(\"Age\")\n",
    "    location = row.get(\"localization\") or row.get(\"location\")\n",
    "    raw_diagnosis = row.get(\"diagnosis\") or row.get(\"dx\") or row.get(\"Histological Diagnosis\") or row.get(\"Clinical Diagnosis\")\n",
    "    diagnosis = diagnosis_mapping.get(str(raw_diagnosis).lower(), str(raw_diagnosis).lower()) if pd.notna(raw_diagnosis) else None\n",
    "\n",
    "    intro = []\n",
    "    has_patient_info = False\n",
    "\n",
    "    if sex and sex != 'nan':\n",
    "        intro.append(f\"Patient is {sex}\")\n",
    "        has_patient_info = True\n",
    "    if pd.notna(age):\n",
    "        try:\n",
    "            age_val = int(float(age))\n",
    "            if sex and sex != 'nan':\n",
    "                intro.append(f\"aged {age_val}\")\n",
    "            else:\n",
    "                intro.append(f\"Patient age is {age_val}\")\n",
    "            has_patient_info = True\n",
    "        except:\n",
    "            pass\n",
    "    if pd.notna(location):\n",
    "        intro.append(f\"with a lesion on the {location.lower()}\")\n",
    "        has_patient_info = True\n",
    "    # if pd.notna(diagnosis):\n",
    "    #     intro.append(f\"diagnosed as {diagnosis}\")\n",
    "\n",
    "    if intro:\n",
    "        if has_patient_info:\n",
    "            parts.append(\" \".join(intro) + \".\")\n",
    "        else:\n",
    "            diagnosis_phrase = [i for i in intro if \"diagnosed as\" in i]\n",
    "            if diagnosis_phrase:\n",
    "                parts.append(f\"This image shows a lesion {diagnosis_phrase[0]}.\")\n",
    "\n",
    "    # Symptoms (PAD)\n",
    "    for symptom in [\"itch\", \"hurt\", \"grew\", \"changed\", \"bleed\"]:\n",
    "        val = str(row.get(symptom, \"\")).lower()\n",
    "        if val in [\"1\", \"true\", \"yes\", \"t\", \"y\"]:\n",
    "            parts.append(f\"Patient reported that the lesion {symptom}s.\")\n",
    "\n",
    "    # PH2-specific structured features (grouped)\n",
    "    ph2_present = []\n",
    "    ph2_absent = []\n",
    "\n",
    "    for field in [\"Asymmetry\", \"Pigment Network\", \"Dots/Globules\", \"Streaks\",\n",
    "                  \"Regression Areas\", \"Blue-Whitish Veil\"]:\n",
    "        val = str(row.get(field, \"\")).strip()\n",
    "        if val:\n",
    "            if val.lower() == \"absent\":\n",
    "                ph2_absent.append(field.lower())\n",
    "            else:\n",
    "                ph2_present.append(f\"{field.lower()} is {val.lower()}\")\n",
    "\n",
    "    if pd.notna(row.get(\"Colors\")):\n",
    "        ph2_present.append(f\"colors observed include {row['Colors'].lower()}\")\n",
    "\n",
    "    if ph2_present:\n",
    "        parts.append(\"The lesion presents the following characteristics: \" + \", \".join(ph2_present) + \".\")\n",
    "    if ph2_absent:\n",
    "        parts.append(f\"Other features such as {', '.join(ph2_absent)} are absent.\")\n",
    "\n",
    "    # DARM features\n",
    "    darm_present = []\n",
    "    darm_absent = []\n",
    "\n",
    "    for field in [\"pigment_network\", \"streaks\", \"pigmentation\", \"regression_structures\",\n",
    "                  \"dots_and_globules\", \"blue_whitish_veil\", \"vascular_structures\"]:\n",
    "        if field in row and pd.notna(row[field]):\n",
    "            val = str(row[field]).strip().lower()\n",
    "            name = field.replace('_', ' ')\n",
    "            if val == \"absent\":\n",
    "                darm_absent.append(name)\n",
    "            else:\n",
    "                darm_present.append(f\"{val} {name}\")\n",
    "\n",
    "    if darm_present:\n",
    "        parts.append(f\"Dermoscopic features include {', '.join(darm_present)}.\")\n",
    "    if darm_absent:\n",
    "        parts.append(f\"Other features such as {', '.join(darm_absent)} are absent.\")\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "def generate_text_prompts(df):\n",
    "    df = df.copy()\n",
    "    df['text_prompt'] = df.apply(create_descriptive_prompt, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Image path creation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:17:35.843385Z",
     "iopub.status.busy": "2025-04-05T09:17:35.843083Z",
     "iopub.status.idle": "2025-04-05T09:17:35.867361Z",
     "shell.execute_reply": "2025-04-05T09:17:35.866606Z",
     "shell.execute_reply.started": "2025-04-05T09:17:35.843357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_image_path(row):\n",
    "    source, image_id = row['dataset_source'], row['image_id']\n",
    "\n",
    "    if source == 'HAM10000':\n",
    "        for part in ['HAM10000_images_part_1', 'HAM10000_images_part_2']:\n",
    "            path = f\"{base_dir}/skin-cancer-mnist-ham10000/{part}/{image_id}.jpg\"\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "\n",
    "    elif source == 'PAD-UFES-20':\n",
    "        for part in [1,2,3]:\n",
    "            path = f\"{base_dir}/skin-cancer/imgs_part_{part}/imgs_part_{part}/{image_id}\"\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "\n",
    "    elif source == 'DERM7PT':\n",
    "        if pd.notnull(row['derm']):\n",
    "            return f\"{base_dir}/derm7pt/release_v0/images/{row['derm']}\"\n",
    "        elif pd.notnull(row['clinic']):\n",
    "            return f\"{base_dir}/derm7pt/release_v0/images/{row['clinic']}\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    elif source == 'PH2':\n",
    "        return f\"{base_dir}/ph2dataset/PH2Dataset/PH2_Dataset_images/{image_id}/{image_id}_Dermoscopic_Image/{image_id}.bmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Augmentation, prompt creation & metadata finalization execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:17:35.868577Z",
     "iopub.status.busy": "2025-04-05T09:17:35.868241Z",
     "iopub.status.idle": "2025-04-05T09:17:48.030538Z",
     "shell.execute_reply": "2025-04-05T09:17:48.029647Z",
     "shell.execute_reply.started": "2025-04-05T09:17:35.868547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pad_df = generate_text_prompts(pad_df)\n",
    "darm_df = generate_text_prompts(darm_df)\n",
    "ham_df = generate_text_prompts(ham_df)\n",
    "ph2_df = generate_text_prompts(ph2_df)\n",
    "\n",
    "# Combine all into one final DataFrame\n",
    "original_text_prompt_df = pd.concat([pad_df, darm_df, ham_df, ph2_df], ignore_index=True)\n",
    "original_text_prompt_df['image_path'] = original_text_prompt_df.apply(generate_image_path, axis=1)\n",
    "print(\"Unified dataset preview:\")\n",
    "print(original_text_prompt_df[['image_id', 'text_prompt', 'image_path']].head().to_string())\n",
    "original_text_prompt_df = original_text_prompt_df.dropna(subset=['diagnosis_numeric'])\n",
    "\n",
    "augmented_metadata_df = pd.read_csv(AUGMENTED_METADATA_PATH)\n",
    "\n",
    "augmented_metadata_df.loc[augmented_metadata_df['original_image_path'].isna() |\n",
    "                         (augmented_metadata_df['original_image_path'] == ''),\n",
    "                         'original_image_path'] = augmented_metadata_df['image_path']\n",
    "\n",
    "merge_df = augmented_metadata_df.merge(\n",
    "    original_text_prompt_df[['image_path', 'text_prompt']],\n",
    "    left_on='original_image_path',\n",
    "    right_on='image_path',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "augmented_text_prompt_df = merge_df[['diagnosis', 'diagnosis_numeric', 'dataset_source', 'original_image_path', 'text_prompt']]\n",
    "augmented_text_prompt_df = augmented_text_prompt_df.rename(columns={\n",
    "    'original_image_path': 'image_path'\n",
    "})\n",
    "\n",
    "original_text_prompt_df.to_csv(\"original_vlm_with_text_prompt_image_path.csv\", index=False)\n",
    "augmented_text_prompt_df.to_csv(\"augmented_vlm_with_text_prompt_image_path.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš™ï¸ Dataloader & Hyperparameters definition, dataset splitting, training & test part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T09:41:24.038128Z",
     "iopub.status.busy": "2025-04-05T09:41:24.037824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "CSV_PATH = \"/kaggle/working/augmented_vlm_with_text_prompt_image_path.csv\"\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 160\n",
    "LR = 1e-4\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_PATH = \"./best_clip_model.pt\"\n",
    "T_MAX = EPOCHS\n",
    "\n",
    "# === AUGMENTATION ===\n",
    "augment_pipeline = A.Compose([\n",
    "    A.RandomResizedCrop((224, 224), scale=(0.8, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ColorJitter(p=0.3),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# === LOAD CSV ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# === CLASS WEIGHTS ===\n",
    "labels = df['diagnosis_numeric'].values\n",
    "classes = np.unique(labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "print(f\"Class Weights: {class_weights}\")\n",
    "\n",
    "# === DATASET ===\n",
    "class VisionLanguageDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image = Image.open(row['image_path']).convert(\"RGB\")\n",
    "        text = str(row['text_prompt'])\n",
    "        label = int(row['diagnosis_numeric'])\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=77  # 77 is the standard for CLIP\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(0),\n",
    "            'label': torch.tensor(int(row['diagnosis_numeric']), dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "# === INIT MODEL ===\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
    "model = CLIPModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "classifier = torch.nn.Linear(model.config.projection_dim, len(classes)).to(DEVICE)\n",
    "\n",
    "# === OPTIMIZER & LOSS ===\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(classifier.parameters()), lr=LR)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
    "\n",
    "# === SPLIT DATA ===\n",
    "total_size = len(df)\n",
    "test_size = int(TEST_SPLIT * total_size)\n",
    "val_size = int(VAL_SPLIT * total_size)\n",
    "train_size = total_size - val_size - test_size\n",
    "\n",
    "train_df, val_df, test_df = random_split(df, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(VisionLanguageDataset(train_df.dataset.iloc[train_df.indices], processor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(VisionLanguageDataset(val_df.dataset.iloc[val_df.indices], processor), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(VisionLanguageDataset(test_df.dataset.iloc[test_df.indices], processor), batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# === TRAINING LOOP ===\n",
    "best_val_accuracy = 0\n",
    "train_losses, val_accuracies, f1_scores = [], [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "        image_embeds = outputs.image_embeds\n",
    "        logits = classifier(image_embeds)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_loss)\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # === VALIDATION ===\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "            image_embeds = outputs.image_embeds\n",
    "            logits = classifier(image_embeds)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(val_labels, torch.nn.functional.one_hot(torch.tensor(val_preds), num_classes=len(classes)), average='weighted', multi_class='ovr')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "\n",
    "    val_accuracy = np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'f1_scores': f1_scores\n",
    "        }, SAVE_PATH)\n",
    "        print(\"Saved new best model!\")\n",
    "\n",
    "    scheduler.step()\n",
    "    new_lr = scheduler.get_last_lr()\n",
    "    print(f\"Epoch {epoch+1}, Updated Learning Rate: {new_lr}\")\n",
    "\n",
    "# === TESTING ===\n",
    "best_model = torch.load(SAVE_PATH)\n",
    "model.load_state_dict(best_model['model_state_dict'])\n",
    "classifier.load_state_dict(best_model['classifier_state_dict'])\n",
    "model.eval()\n",
    "classifier.eval()\n",
    "\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "        image_embeds = outputs.image_embeds\n",
    "        logits = classifier(image_embeds)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# === REPORT ===\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "print(classification_report(test_labels, test_preds, target_names=[str(c) for c in classes]))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3904493,
     "sourceId": 6785866,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4259963,
     "sourceId": 7337662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6892992,
     "sourceId": 11062562,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
